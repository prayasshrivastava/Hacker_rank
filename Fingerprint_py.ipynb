{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fingerprint.py",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prayasshrivastava/Hacker_rank/blob/master/Fingerprint_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XaKb8LClfqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSzzir_TFoUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr4Z5LUUFp7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfCzPJJPF19n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pylab as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fYJEjofGJ_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErQwJG2QGT4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_size1=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgKpgy_PGxUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filters1=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdJOBn-CG4SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_size2=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqNdjb__G93z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filters2=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEnSPthAHC_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc_size=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-JOOfMfHTwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape=[374,388]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_rE04HMHjQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch=500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk9OjWS9Host",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMPEii6wHrcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7vDlu2CHtsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folders=glob.glob('C:\\Users\\HP\\Desktop\\Prayas(53)\\PNG')\n",
        "\n",
        "imagenames_list=[]\n",
        "\n",
        "labels=[]\n",
        "\n",
        "imagenames_list=[]\n",
        "\n",
        "count=0\n",
        "\n",
        "for folder in folders:\n",
        "  for f in glob.glob(folder+'/*.tif'):\n",
        "    imagenames_list.append(f)\n",
        "    lebels.append(count)\n",
        "    \n",
        "  count+=1\n",
        "  \n",
        "read_imges=[]\n",
        "Tensor_input=[]\n",
        "for image in imagenames_list:\n",
        "  read_images.append(cv2.imread(image, cv2.IMREAD_GRAYSCALE))\n",
        "  \n",
        "Labels=tf.keras.utils.to_categorical(\n",
        "    labels,\n",
        "    num_classes=None)\n",
        "\n",
        "df new_weights(shape):\n",
        "  return tf.variable(tf.truncated_normal(shape,stddev=0.5))\n",
        "\n",
        "df new_biases(length):\n",
        "  return tf.variable(tf.constant(0.05, shape=[length]))\n",
        "\n",
        "def new conv layer(input,\n",
        "                   num_input_channels,\n",
        "                  filter_size,\n",
        "                  num_filters,\n",
        "                  use_pooling=True):\n",
        "    \n",
        "    shape=[filter_size, filter_size, num_input_channels, num_filters]\n",
        "    \n",
        "    weights=new_weights(shape=shape)\n",
        "    \n",
        "    biases=new biases(length=num filters)\n",
        "    \n",
        "    layer= tf.nn.conv2d(input=input,\n",
        "                       filter=weights,\n",
        "                       strides=[1,1,1,1],\n",
        "                       padding='SAME')\n",
        "    \n",
        "    layer += biases\n",
        "    \n",
        "    if use_pooling:\n",
        "      \n",
        "      layer= tf.nn.max_pool(value=layer,\n",
        "                           ksize=[1,2,2,1],\n",
        "                           strides=[1,2,2,1],\n",
        "                           padding='SAME')\n",
        "      \n",
        "      layer=tf.nn.relu(layer)\n",
        "      \n",
        "      return layer, weights\n",
        "    \n",
        "    \n",
        "def flattern_layer(layer):\n",
        "  \n",
        "    layer_shape=layer.ger_shape()\n",
        "  \n",
        "    num features=layer shape[1:4].num elements()\n",
        "  \n",
        "    layer_flat = tf.reshape(layer,[-1, num_features])\n",
        "  \n",
        "    return layer_flat, num_features\n",
        "\n",
        "\n",
        "def new_fc_layer(input,\n",
        "                num_inputs,\n",
        "                num_outputs,\n",
        "                use_relu=True):\n",
        "  \n",
        "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
        "    \n",
        "    biases= new_biases(length=num_outputs)\n",
        "    \n",
        "    layer=tf.matmul(input, weights) +biases\n",
        "    \n",
        "    if use_relu:\n",
        "        layer = tf.nn.relu(layer)\n",
        "        \n",
        "    return layer\n",
        "  \n",
        "\n",
        "  \n",
        "x=tf. placeholder(tf.float32, shape=[None, 374,388], name='x')\n",
        "\n",
        "x_image = tf.reshape(x. [-1,374,388,1])\n",
        "\n",
        "y_true=tf.placeholder(tf.float32, shape=[none,10], name='y_true')\n",
        "\n",
        "y_true_cls= tf.argmax(y_true, axis=1)\n",
        "\n",
        "layer_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
        "                                           num_input_channels=1,\n",
        "                                           filter_size=filter_size1,\n",
        "                                           num_filters=num_filters1,\n",
        "                                           use_pooling=True)\n",
        "\n",
        "layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1,\n",
        "                                           num input channels=num filters1,\n",
        "                                           filter_size=filter_size2,\n",
        "                                           num_filters=num_filters2,\n",
        "                                           use_pooling=True)\n",
        "\n",
        "layer_flat, num_features = flatten_layer(layer_conv2)\n",
        "\n",
        "layer_fc1=new_fc_layer(input=layer_flat,\n",
        "                      num_inputs=num_features,\n",
        "                      num_outputs=10,\n",
        "                      use_relu=True)\n",
        "\n",
        "y_pred = tf.nn.softmax(layer_fc1)\n",
        "summary_d_x_hist = tf.summary.histogram(\"y pred\", y_pred)\n",
        "\n",
        "y_pred_cls = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc1,\n",
        "                                                       label=y_true)\n",
        "\n",
        "summary_d_loss = tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
        "\n",
        "cost=tf.reduce_mean(cross_entropy)\n",
        "\n",
        "summary_COST_loss = tf.summary.scalar(\"cost\",cost)\n",
        "\n",
        "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
        "\n",
        "accuracy=tf.reduce mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "summary_accuracy = tf.summary.scalar(\"accuracy\", accuracy)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=le.2).minimize(cost)\n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    sess.run(init)\n",
        "    saver = tf.train.saver()\n",
        "    \n",
        "    merged = tf.summary.merge_all()\n",
        "    \n",
        "    writer = tf.summary.Filewriter('./logs', sess.graph)\n",
        "    \n",
        "    for i in range(1,epoch):\n",
        "        \n",
        "        batch_ss=read_images[j:batch+j]\n",
        "        labels_ss=Labels[j:batch+j]\n",
        "        \n",
        "        j+=batch\n",
        "        \n",
        "        if j+batch>=len(read_images):\n",
        "            j=0\n",
        "            \n",
        "        feed_dict_train = {x: batch_ss,\n",
        "                           y_true: labels_ss}\n",
        "        \n",
        "        summary_loss,loss=sess.run([summary_COST_loss,cost],feed_dict=feed_dict_train)\n",
        "        \n",
        "        summary_hist,predictio=sess.run([summary_d_x_hist,y_pred],feed_dict=feed_dict_train)\n",
        "        \n",
        "        \n",
        "        print(loss)\n",
        "        \n",
        "        sess.run(optimizer,feed_dict=feed_dict_train)\n",
        "        \n",
        "        summary_acc, acc = sess.run([summary_accuracy, accuracy], feed dict=feed_dict_train)\n",
        "        \n",
        "        if i % 2 == 0:\n",
        "          \n",
        "          acc=sess.run(accuracy,feed_dict=feed_dict_train)\n",
        "          \n",
        "          msg= \"optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
        "          \n",
        "          print(msg.format(i+1,acc))\n",
        "          \n",
        "        saver.save(sess,'./logs/model.jpg',i)\n",
        "        \n",
        "        \n",
        "          \n",
        "            \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  \n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAQlKdsM2Pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEkCZx5gL-yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}